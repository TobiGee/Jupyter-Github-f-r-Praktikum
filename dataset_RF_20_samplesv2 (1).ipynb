{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Exercise Sheets BCI\n",
    "\n",
    " ## Good Afternoon all together.\n",
    " Todays obejctive is, to write a random forrest classifier. Just that the classifier is already written.\n",
    " Hence you objectives are:\n",
    " - In this code some improvements can be made in respect to programming paradigms.\n",
    " - Also please explain for every code snippet whats happening.\n",
    " - Then visualise one EEG chanel with matplotlib\n",
    " - Last find the missing part in the code and correct it\n",
    "\n",
    " Good Luck and much fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pywt\n",
    "from scipy.stats import entropy\n",
    "import plotly.express as px\n",
    "import math\n",
    "import neurokit2 as nk\n",
    "\n",
    "df = pd.read_csv('20200605_2030.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Event Id\"].dropna() # Well. darn it no other labels to use / Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This creates a 2d list of the dataframe, prints the length of the first dimension and then prints the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Are these \"labels\" ? Why are they using Channel 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awakedf = df[:37502]\n",
    "tireddf = df[308386:345889]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awake = awakedf[\"Channel 4\"] # Only use Channel 4?\n",
    "tired = tireddf[\"Channel 4\"] # Okay\n",
    "entropy_awake = nk.entropy_sample(awake) # Check the \"variablity\" of the series\n",
    "print(entropy_awake)\n",
    "entropy_tired = nk.entropy_sample(tired) # Check the \"variablity\" of the series or the \"sample entropy\"\n",
    "print(entropy_tired)\n",
    "print(len(awake))\n",
    "entropy_awake = nk.entropy_approximate(awake) # same as above but faster.\n",
    "print(entropy_awake)\n",
    "entropy_tired = nk.entropy_approximate(tired)\n",
    "print(entropy_tired)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Of interrest is that the entropy is smaller on tired probants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for chunks\n",
    "def datasetChunkGenerator(df, start, chunksize):\n",
    "    index = 0\n",
    "    while index + chunksize < len(df):\n",
    "        yield df[index:index+chunksize]\n",
    "        index += chunksize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_sample=[]\n",
    "entropy_approximate=[]\n",
    "\n",
    "for chunk in datasetChunkGenerator(df[\"Channel 4\"], 0, 10000):\n",
    "    entropy_sample.append(nk.entropy_sample(chunk))\n",
    "    entropy_approximate.append(nk.entropy_approximate(chunk))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, y=\"Channel 4\", hover_data=df.columns)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df, y=\"Channel 4\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,0,1,0]\n",
    "print(len(labels)) # labels.. not sure if they fit for the actual entropy stuff or the overwritten stuff\n",
    "# A big problem I see here is that the Data is heavily biased. As a Classifier I'd just always say 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'sample':entropy_sample,\n",
    "    'approximate':entropy_approximate\n",
    "}) # why use both? They represent a similar thing\n",
    "fig = px.line(data)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Needed to be adapted to use the labels.. but who knows what those labels correspond too\n",
    "X = data[['sample','approximate']][:20]  # Features ... not sure why we used sample and the approximate\n",
    "y = labels  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,z in zip(X_train[\"sample\"],X_train[\"approximate\"],y_train):\n",
    "    print(x,y,z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,z in zip(X_test[\"sample\"],X_test[\"approximate\"],y_test):\n",
    "    print(x,y, z)\n",
    "\n",
    "# Here we can see that we lost the entropy -> tiredness corralation ... probably a problem with the labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummydata to check the predictor\n",
    "data2 = pd.DataFrame({\n",
    "    'sample':np.arange(0,1,0.01),\n",
    "    'approximate':np.arange(0,1,0.01),\n",
    "})\n",
    "display(data2.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clf.predict(data2)\n",
    "\n",
    "fig = px.line(y)\n",
    "fig.show()\n",
    "\n",
    "# not sure what this tells me....but to much or to little entropy equals tired? \n",
    "\n",
    "# This changes drastically depending upon the train/test shuffle \n",
    "\n",
    "# If id had to guess id say that my labels are not accurate and depending on which get trained the model is drastically different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
